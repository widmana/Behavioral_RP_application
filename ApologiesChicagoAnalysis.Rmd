---
title: "Behavioral RP Recruiting: Apologies Survey Analysis"
author:
date: "2024-01-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, results = "hide"}
# installing packages
install.packages("tidyverse", repos = "https://cloud.r-project.org")
install.packages("vader", repos = "https://cloud.r-project.org")
install.packages("readxl", repos = "https://cloud.r-project.org")
install.packages("car", repos = "https://cloud.r-project.org")
library(readxl)
library(tidyr)
library(car)
library(tidyverse)
library(vader)

# loading data:
excel_file <- "ApologiesData.xlsx"
  # separating sheets
all_sheets <- lapply(excel_sheets(excel_file), function(sheet) {
  read_excel(excel_file, sheet = sheet)
})
description <- read_excel(excel_file, sheet = 1)
apology_data <- read_excel(excel_file, sheet = 2)
```

```{r, echo = FALSE, results = "hide"}
## cleaning data/excluding observations:

# check consent 
table(apology_data$consent) #no DISAGREEs

# exclude "progress" that was less than 50
table(apology_data$Progress)
apology_data_high_progress <- apology_data[apology_data$Progress >= 50, ]

# attention checks (passed_attn)
table(apology_data_high_progress$passedattn)
apology_data_attention_check <- apology_data_high_progress[apology_data_high_progress$passedattn == "yes", ]

# check for duplicate IP addresses
table(apology_data_attention_check$IPAddress)
matching_indices <- which(apology_data_attention_check$IPAddress == "50.237.5.2")
print(apology_data_attention_check[matching_indices, ]) #looks like the data wasn't copied. I decided to keep these instances since we already have a limited dataset. The participants may be in the same household or using the same computer.

# exclude observations where the time completed or age was an outlier
time_completed_z <- scale(apology_data_attention_check$`Duration (in seconds)`)
age_z <- scale(apology_data_attention_check$age)
  # define threshold for outliers (common convention)
outlier_threshold <- 3
  # find and exclude outliers for time completed and age
time_completed_outliers <- which(abs(time_completed_z) > outlier_threshold)
age_outliers <- which(abs(age_z) > outlier_threshold)
print(apology_data_attention_check[time_completed_outliers, ])
print(apology_data_attention_check[age_outliers, ])
outlier_indices <- union(time_completed_outliers, age_outliers)
  # final df
filtered_apology_data <- apology_data_attention_check[-outlier_indices, ]
```

```{r, echo = FALSE, results = "hide"}
## restructuring data ("long" version):
#participant | indicator | scenario              | feelings
#1             never       feelings_youalone       -30-+30
#1             never       feelings_bothyoufirst   -30-+30
#etc.

long_apology_data <- pivot_longer(filtered_apology_data,
                                  cols = c(feelings_youalone, feelings_bothyoufirst, feelings_themalone, feelings_boththemfirst, feelings_neither, feelings_youaloneforgiven),
                                  names_to = "scenario",
                                  values_to = "feelings")
```

# Task 1: Answer a Research Question

## (1) Do people care about getting a return apology after being the first to apologize?

We are testing to see whether there is a significant difference between the mean rated feeling when a participant is presented with two scenarios: (1) feelings_youalone: the participant apologizes without a return apology and (2) feelings_bothyoufirst: the participant apologizes and the opposing party apologizes after. We will be using a one-way ANOVA test to check for a significant difference between these two means.

$\mu_1$ = mean of feelings for "feelings_youalone" (the participant apologizes without a return apology)

$\mu_2$ = mean of feelings for "feelings_bothyoufirst" (the participant apologizes and the opposing party apologizes after)

Null hypothesis: $H_0$:$\mu_1 = \mu_2$

Alternate hypothesis: $H_1$: $\mu_1 \neq \mu_2$

```{r, echo = FALSE}
## significance testing:
apology_data_youfirst <- long_apology_data[long_apology_data$scenario %in% c("feelings_youalone", "feelings_bothyoufirst"), ]

model <- aov(feelings ~ scenario, data = apology_data_youfirst)
summary(model)
```
The one-way ANOVA test shows that there is a significant difference between the mean rated feeling in the two presented scenarios (p-value = 7.89*10<sup>-15</sup> < 0.05). This implies that people who apologize first feel significantly different about the situation when they receive a return apology and when they don't.

```{r, echo = FALSE}
## check assumptions (normality, variance (already assume independence and random sampling))
  # check normality
residuals <- residuals(model)

par(mfrow = c(1, 2))
qqnorm(residuals)
shapiro.test(residuals)  # Perform Shapiro-Wilk test
  # check variance
plot(model, 1)  # Residuals vs. Fitted values plot
    #suggests that the data has too much variance --> might not have enough data
```

The normality and variance conditions of the model are met. 

```{r, echo = FALSE}
tukey_result <- TukeyHSD(model)
print(tukey_result)
```

We are 95% confident that the mean rated feeling of the participant when apologizing alone is between 31.77 and 20.63 points less than the mean rated feeling of the participant when apologizing first followed by the opposing party's apology. 

## (2) Does this vary as a function of individual differences in “initiator type”?

We are testing to see whether there is a significant interaction effect between the initiator type and scenario on rated feeling. We will be using a two-way ANOVA test to test for a significant difference between the means of each initiator type and scenario combination.

$\mu_{i:j}$ = mean when scenario is "i" (i: 1-6) and initiator type is "j" (j: 1-3)

Null hypothesis: $H_0$: $\mu_{i:j}$ = $\mu_{1:1}$ = $\mu_{1:2}$... = $\mu_{2:1}$... = $\mu_{6:3}$

Alternate hypothesis: $H_1$: at least one $\mu_{i:j}$ $\neq$ $\mu_{i:j}$

```{r, echo = FALSE}
## significance testing:
# Fit the two-way ANOVA model
model2 <- aov(feelings ~ scenario * initiator_type, data = apology_data_youfirst)
summary(model2)
```

From this two-way ANOVA test, we can see that although scenario and initiator type are both independently significant to the mean rated feeling, with p-values of 1.53*10<sup>^-15</sup> and 0.00413 respectively, they do not have a significant interaction (p-value = 0.67311). This implies that the effect of the scenario on rated feeling is consistent no matter what the self-declared initiator type was. This also implies that the effect of initiator type on rated feeling is consistent no matter what the scenario was. The relationship between scenario and initiator type does not significantly affect the rated feeling. 

```{r, echo = FALSE}
## significance test (initiator type)
model_initiator <- aov(feelings ~ initiator_type, data = apology_data_youfirst)
summary(model_initiator)
```

In order to test initiator_type's significance to rated feeling more independently, we conducted an additional one-way ANOVA test. This produced a non-significant p-value of 0.0648. Due to the discrepancies in p-values (0.00413 from the two-way ANOVA test vs 0,0648 from the one-way ANOVA test), we are hesitant to say that there is sufficient enough evidence to reject the main effect null hypothesis, which states that the mean rated feeling among initiator_types are equal.

```{r, echo = FALSE}
## check assumptions (normality, variance (already assume independence and random sampling))
  # check normality
residuals <- residuals(model2)
par(mfrow = c(1, 2))
qqnorm(residuals)
shapiro.test(residuals)  # Perform Shapiro-Wilk test
  # check variance
plot(model2, 1)  # Residuals vs. Fitted values plot
```

The normality and variance conditions of the model are met. We will not be conducting a Tukey Test since the interaction effect is non-significant.

## (3) Is a return apology simply viewed as a form of forgiveness?

We are testing to see whether there is a significant difference between the mean rated feeling when a participant is presented with two scenarios: (1) the participant apologizes and receives forgiveness and (2) the participant apologizes and the opposing party apologizes after. We will be using a one-way ANOVA test to check for a significant difference between these two means.

$\mu_1$ = mean of feeling for "feelings_youaloneforgive" (the participant apologizes and receives forgiveness)

$\mu_2$ = mean of feeling for "feelings_bothyoufirst" (the participant apologizes and the opposing party apologizes after)

Null hypothesis: $H_0$:$\mu_1 = \mu_2$

Alternate hypothesis: $H_1$: $\mu_1 \neq \mu_2$
  
```{r, echo = FALSE}
## significance testing:
apology_data_return <- long_apology_data[long_apology_data$scenario %in% c("feelings_youaloneforgiven", "feelings_bothyoufirst"), ]

model3 <- aov(feelings ~ scenario, data = apology_data_return)
summary(model3)
```
The one-way ANOVA test shows that there is a significant difference (p-value = 9.25*10<sup>-10</sup> < 0.05) between the mean rated feeling in the two presented scenarios. This implies that people who apologize first and receive forgiveness feel significantly different about the situation than when they receive a return apology.

```{r, echo = FALSE}
## check assumptions (normality, variance (already assume independence and random sampling))
  # check normality
residuals <- residuals(model3)
par(mfrow = c(1, 2))
qqnorm(residuals)
shapiro.test(residuals)  # Perform Shapiro-Wilk test
  # check variance
plot(model3, 1)  # Residuals vs. Fitted values plot
    #suggests that the data has too much variance --> might not have enough data
```

The normality and variance conditions of the model are met.

```{r, echo = FALSE}
tukey_result <- TukeyHSD(model3)
print(tukey_result)
```

We are 95% confident that the rated feeling of the participant apologizing alone and receiving forgiveness is between 21.76 and 28.06 points less than the rated feeling of the participant apologizing first followed by the opposing party's apology. This implies that people don't see a return apology simply as a form of forgiveness. People prefer receiving a return apology rather than just forgiveness. 

# Task 2 - Conduct additional analyses

## (a) Produce a single bar graph that shows the average of the “feelings” variable for all six scenarios, in order of decreasing value. Include error bars (standard errors or confidence intervals). Label fully. Describe your observations in 1-2 sentences.

```{r, echo = FALSE}
avg_feelings <- tapply(long_apology_data$feelings, long_apology_data$scenario, mean)
table(avg_feelings)
ordered_scenarios <- names(sort(avg_feelings, decreasing = TRUE))
std_errors <- tapply(long_apology_data$feelings, long_apology_data$scenario, function(x) sd(x) / sqrt(length(x)))
print(std_errors)

par(mar=c(5.1, 13 ,4.1 ,2.1))

# Create the bar plot
bp <- barplot(avg_feelings[ordered_scenarios], 
        main = "Average Feelings Score by Scenario",
        names.arg = ordered_scenarios,
        col = "skyblue",
        border = "black",
        xlim = c(-20, 20),  # Set the x-axis limits to -20 to +20
        horiz = TRUE,
        las = 1)

# Add standard error bars
for (i in 1:length(ordered_scenarios)) {
  arrows(x0 = avg_feelings[ordered_scenarios][i] - std_errors[i], 
         x1 = avg_feelings[ordered_scenarios][i] + std_errors[i], 
         y0 = bp[i], 
         y1 = bp[i], 
         angle = 90, 
         code = 3, 
         length = 0.1)
}

# Add margin text for x-axis label
mtext("Average Feelings Score", side = 1, line = 3)

# Add margin text for y-axis label
mtext("Scenario", side = 2, line = 11.5)
```

The mean ranked feeling is worse for scenarios in which the participant apologizes alone or there is no apology (feelings_youalone, feelings_youaloneforgiven, feelings_neither). People much prefer scenarios in which both parties end up apologizing rather than anyone apologizing alone, including the opposing party apologizing alone. 

## (b) Conduct a one way ANOVA to determine if there are differences in feelings across the six scenarios. Then perform pairwise t-tests to compare “feelings_youalone” to the other five scenarios. Describe your conclusions in 1-2 sentences.

```{r, echo = FALSE}
## ANOVA Test
model4 <- aov(feelings ~ scenario, data = long_apology_data)
summary(model4)

  # check assumptions (normality, variance (already assume independence and random sampling))
residuals <- residuals(model4)
par(mfrow = c(1, 2))
qqnorm(residuals)
shapiro.test(residuals)  # Perform Shapiro-Wilk test
  # check variance
plot(model4, 1)  # Residuals vs. Fitted values plot
    #suggests that the data has too much variance --> might not have enough data

tukey_result <- TukeyHSD(model4)
print(tukey_result)
```

```{r, echo = FALSE}
# Perform pairwise t-test
result <- pairwise.t.test(long_apology_data$feelings, long_apology_data$scenario,
                          p.adjust.method = "bonferroni")
print(result$p.value[4, ])
```

The ANOVA test found there is sufficient evidence to conclude that at least one of the scenarios' rated feeling means is significantly different from another (p-value = <2*10<sup>-16</sup> < 0.05). The t-test has found that there is sufficient evidence to conclude that there is a significant difference in the rated feelings between the feelings_youalone scenario and the feelings_boththemfirst, feelings_bothyoufirst, and feelings_themalone scenarios. The feelings_youalone scenario's only non-significant mean rated feeling difference was with feelings_neither.

## (c) Create a graph showing the proportion of people choosing each of the different options for the following variable: outcome_binary1. Conduct a test to determine if the proportion differences across the answers are significantly different from one another.

```{r, echo = FALSE}
# Calculate proportions
proportions <- prop.table(table(long_apology_data$outcome_binary1))

#par(mar=c(5.1, 13 ,4.1 ,2.1))

# Create a bar plot
barplot(proportions, 
        main = "Proportion of Responses for outcome_binary1",
        xlab = "Outcome",
        ylab = "Proportion",
        col = "skyblue",
        ylim = c(0, 1),
        names.arg = c("I apologize first, then they apologize", "Neither I nor they apologize"))  # Specify custom x-axis labels

# Perform chi-squared test
chi_sq_test <- chisq.test(table(long_apology_data$outcome_binary1))
print(chi_sq_test)
```
There is sufficient evidence to conclude that there is a significant difference between the proportion of people choosing "I apologize first, then they apologize" to outcome_binary1 and the proportion of people choosing "Neither I nor they apologize" to outcome_binary1. This implies that people were much more likely to choose to apologize first followed by an opposing party apology than to choose for neither party to apologize. 

## (d) OPTIONAL–This NLP exercise is optional, and primarily relevant to Professors Chaudhry and Kirgios.oNatural Language Processing (NLP) exercise: Find a way to analyze the sentiment and/or emotions present in the free form text responses in the “describe” variable. For instance, you may use packages like VADER, TextAnalyzer, or LIWC (or others). You might even use ChatGPT (in your code; not manually). Describe your observations in a few sentences.

I want to learn how to do this! Right now, I'm not sure how. 
